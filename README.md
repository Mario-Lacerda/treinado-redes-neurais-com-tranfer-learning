# Desafio Dio - Treinamento de Redes Neurais com Transfer Learning



**Treinamento de Redes Neurais com Transfer Learning: Um Projeto Abrangente com C√≥digos**

### **Introdu√ß√£o**

O treinamento de redes neurais com transfer√™ncia de aprendizagem √© uma t√©cnica poderosa que pode melhorar significativamente o desempenho de uma rede neural em uma nova tarefa. Isso pode ser √∫til quando voc√™ tem uma grande quantidade de dados para uma tarefa, mas n√£o tem muitos dados para a outra tarefa.



#### **Como funciona a transfer√™ncia de aprendizagem?**

Para treinar uma rede neural com transfer√™ncia de aprendizagem, voc√™ primeiro precisa treinar uma rede neural na primeira tarefa. Em seguida, voc√™ pode usar os pesos da rede neural treinada como ponto de partida para treinar uma nova rede neural na segunda tarefa.

Os pesos de uma rede neural s√£o os valores que determinam como a rede processa os dados. Ao usar os pesos de uma rede neural treinada como ponto de partida, voc√™ pode evitar que a nova rede neural tenha que aprender tudo do zero. Isso pode economizar muito tempo e esfor√ßo.



#### **Quando usar a transfer√™ncia de aprendizagem?**



A transfer√™ncia de aprendizagem pode ser uma boa op√ß√£o se voc√™ tiver as seguintes condi√ß√µes:

- Voc√™ tem uma grande quantidade de dados para uma tarefa, mas n√£o tem muitos dados para outra tarefa.

- As duas tarefas s√£o semelhantes.

  

#### **Como implementar a transfer√™ncia de aprendizagem?**

Existem v√°rias maneiras de implementar a transfer√™ncia de aprendizagem. Uma maneira comum √© usar uma biblioteca de aprendizado de m√°quina como TensorFlow ou PyTorch. Essas bibliotecas fornecem fun√ß√µes que facilitam a transfer√™ncia de pesos de uma rede neural para outra.



#### **Exemplo**

Aqui est√° um exemplo de como treinar uma rede neural com transfer√™ncia de aprendizagem usando TensorFlow:

python

```python
import tensorflow as tf

# Carregar a rede neural pr√©-treinada
pre_trained_model = tf.keras.applications.VGG16(include_top=False, input_shape=(224, 224, 3))

# Congelar as camadas da rede neural pr√©-treinada
for layer in pre_trained_model.layers:
    layer.trainable = False

# Adicionar novas camadas √† rede neural
new_model = tf.keras.Sequential([
    pre_trained_model,
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Compilar o novo modelo
new_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Treinar o novo modelo
new_model.fit(x_train, y_train, epochs=10)
```



Neste exemplo, estamos usando uma rede neural VGG16 pr√©-treinada no conjunto de dados ImageNet. Congelamos as camadas da rede neural pr√©-treinada para que n√£o sejam atualizadas durante o treinamento. Em seguida, adicionamos novas camadas √† rede neural para que possa ser treinada na nova tarefa.



## **Conclus√£o**



A transfer√™ncia de aprendizagem √© uma t√©cnica poderosa que pode melhorar significativamente o desempenho de uma rede neural em uma nova tarefa. √â uma t√©cnica relativamente f√°cil de implementar e pode ser usada para uma ampla gama de tarefas.



**C√≥digos adicionais**

Aqui est√£o alguns c√≥digos adicionais que voc√™ pode achar √∫teis:



- **Carregar um modelo pr√©-treinado:**

python

```python
pre_trained_model = tf.keras.applications.load_model('path/to/pre_trained_model.h5')
```



- **Congelar as camadas de um modelo:**

python

```python
for layer in model.layers:
    layer.trainable = False
```



- **Adicionar novas camadas a um modelo:**

python

```python
new_model = tf.keras.Sequential([
    model,
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
```



- **Compilar um modelo:**

python

```python
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
```



- **Treinar um modelo:**

python

```python
model.fit(x_train, y_train, epochs=10)
```





# Treinamento de Rede Neural Artificial





![ezgif com-gif-maker](https://user-images.githubusercontent.com/67600860/136825544-05c9b3d4-d5ce-4e81-a4c9-0b30acb13628.gif)



<p align="justify">
üíª Como trabalho proposto na disciplina Redes Neurais Artificiais da gradua√ß√£o em Engenharia El√©trica, este √© um c√≥digo b√°sico que implementa, passo a passo, o processo de treinamento de uma Perceptron de M√∫ltiplas Camadas por meio do algoritmo backpropagtion. Para isso, foi utilizado um banco de dados conhecido para problemas de classifica√ß√£o, o dataset <a href="https://archive.ics.uci.edu/ml/datasets/iris">Iris</a> üåº

</p>



## OBS: 

O c√≥digo tem por objetivo exemplificar a etapa de treino üèãüèæ‚Äç‚ôÄ e atualiza√ß√£o dos pesos com c√≥digo pr√≥prio, as outras etapas importantes como valida√ß√£o cruzada e teste n√£o est√£o presentes neste c√≥digo.





# Modelo de Neur√¥nio

<p align="justify">
O neur√¥nio √© a unidade b√°sica morfofuncional do tecido nervoso e, da
mesma maneira, √© a unidade b√°sica de processamento da rede neural. Estes
modelos computacionais inspirados em neur√¥nios biol√≥gicos possuem
algumas caracter√≠sticas semelhantes aos naturais para poder desfrutar da
capacidade de aprendizado, s√£o elas: sinais de entrada, pesos sin√°pticos,
fun√ß√£o de soma, fun√ß√£o de ativa√ß√£o e sinal de sa√≠da.
Para realizar esse processo em uma linguagem de programa√ß√£o, √©
aconselh√°vel utilizar opera√ß√µes matriciais, pois assim ocorre uma otimiza√ß√£o
na etapa de compila√ß√£o. Teremos ent√£o, um vetor de entrada e um vetor de
pesos (ou matriz, caso haja mais de um neur√¥nio na camada).
</p>


![neuronio](https://user-images.githubusercontent.com/67600860/136829925-bfd180e6-f59b-4901-85d3-a3c2a8d2a98b.png)





# Forma de Aprendizado



<p align="justify">
Os pesos sin√°pticos s√£o pe√ßas fundamentais para o armazenamento de
informa√ß√£o do neur√¥nio artificial, √© atrav√©s deles que o modelo possui a
capacidade de aprender. Utiliza-se o algoritmo de Backpropagation,
que possibilita o ajuste dos pesos em camadas intermedi√°rias, fazendo a
chamada ‚Äúretropropaga√ß√£o do erro‚Äù, ou seja, utiliza o valor do erro da
camada de sa√≠da no ajuste dos pesos das outras camadas ocultas.
 </p>




# Algoritmo Backpropagation



<p align="justify">
A inicializa√ß√£o dos pesos sin√°pticos ocorre de maneira rand√¥mica, a
escolha dos pesos iniciais pode prevenir o problema do m√≠nimo local e ainda
a satura√ß√£o prematura da rede. O fluxo de informa√ß√£o acontece em duas
etapas, primeiramente na etapa "forward", a rede √© apresentada aos padr√µes
de treinamento e tem seus pesos excitados a produzir uma sa√≠da, na etapa
‚Äúbackward‚Äù, calcula-se o erro da rede para aquele padr√£o e este erro, ent√£o, √©
"retro propagado" para as outras camadas ocultas da rede, que n√£o tem
acesso direto ao erro da camada de sa√≠da. √â nesta etapa que os pesos s√£o atualizados e a rede adquire conhecimento, o processo se repete at√© que o
crit√©rio de parada seja satisfeito (o crit√©rio adotado foi o de n√∫mero de
√©pocas de treinamento).
</p>


**A imagem abaixo faz um resumo geral das etapas do c√≥digo**



<p align="center">
  <img src="https://user-images.githubusercontent.com/67600860/136827442-aff9e61d-ec4c-437f-98d6-1b8e20688ff6.png" />
</p>




# Gr√°ficos



*Os gr√°ficos apresentados a seguir tem por finalidade melhorar a compreens√£o dos processos executados e a import√¢ncia de cada um. Para gerar estes gr√°ficos, utilizou-se 5 neur√¥nios na camada escondida, 300 √©pocas e taxa de aprendizado de 0.01*



* Imagem 1 - Evolu√ß√£o do erro por n√∫mero de √©pocas

  

<p align="center">
  <img src="https://user-images.githubusercontent.com/67600860/136830197-fa51fda2-5f17-40d4-9f6f-7149d4c4f9ec.jpg" />
</p>
<p align="justify">
Esta imagem mostra a magnitude do erro quadr√°tico m√©dio para cada n√∫mero de √©pocas, onde o erro se inicia em aproximadamente 0.04 e finaliza em aproximadamente 0.015 na √©poca de n√∫mero 300
</p>



* Imagem 2 - Sa√≠da desejada e sa√≠da de treinamento

<p align="center">
  <img src="https://user-images.githubusercontent.com/67600860/136830662-dc29ecb8-bbc2-4a29-956f-a7a4e7a25b9a.jpg" />
</p>

<p align="justify">
Apresenta os valores de sa√≠da do treinamento (c√≠rulo azul) sobrepostos aos valores de sa√≠da desejado (asterisco verde) para as classes 1 (Iris Setosa), 2 (Iris
Versicolour) e 3 (Iris Virginica). Note que esta imagem n√£o representa a classifica√ß√£o final, j√° que os valores est√£o plotados de maneira cont√≠nua. Para performar a classifica√ß√£o, poder√≠amos por exemplo instituir limites de valores para as classes, sendo a classe 1 correspondendo aos valores de sa√≠da entre 0.5 e 1.5, a classe 2 aos valores de 1.5 a 2.5 e a classe 3 aos valores entre 2.5 e 3.5
 </p>



* Imagem 3 - Sa√≠das e √©pocas

  

<p align="center">
  <img src="https://user-images.githubusercontent.com/67600860/136830937-b0bf0b76-0ec7-4e6d-b08b-50e3bf7ea43b.jpg" />
</p>

<p align="justify">
A finalizade desta imagem √© proporcionar o "feeling" sobre como as classifica√ß√µes v√£o se ajustando e ficando melhor √† medida que o n√∫mero de √©pocas aumenta. Na imagem podemos observar que as classifica√ß√µes come√ßam muito dispersas e se concentram √† medida que os pesos se ajustam
 </p>




## **Caracter√≠sticas Gerais das Redes Neurais**


Uma rede neural artificial √© composta por v√°rias unidades de processamento, cujo funcionamento √© bastante simples. Essas unidades, geralmente s√£o conectadas por canais de comunica√ß√£o que est√£o associados a determinado peso. As unidades fazem opera√ß√µes apenas sobre seus dados locais, que s√£o entradas recebidas pelas suas conex√µes. O comportamento inteligente de uma Rede Neural Artificial vem das intera√ß√µes entre as unidades de processamento da rede.



A opera√ß√£o de uma unidade de processamento, proposta por McCullock e Pitts em 1943, pode ser resumida da seguinte maneira:



- Sinais s√£o apresentados √† entrada;

  

- Cada sinal √© multiplicado por um n√∫mero, ou peso, que indica a sua influ√™ncia na sa√≠da da unidade;

  

- √â feita a soma ponderada dos sinais que produz um n√≠vel de atividade;

  

- Se este n√≠vel de atividade exceder um certo limite (threshold) a unidade produz uma determinada resposta de sa√≠da.

  

![img](https://sites.icmc.usp.br/andre/research/neural/image/mccul.gif)



#### *Esquema de unidade McCullock - Pitts.*



Suponha que tenhamos p sinais de entrada X1, X2, ..., Xp e pesos w1, w2, ..., wp e limitador t; com sinais assumindo valores booleanos (0 ou 1) e pesos valores reais.



#### Neste modelo, o n√≠vel de atividade a √© dado por:

a = w1X1 + w2X2 + ... + wpXp

A sa√≠da y √© dada po

- y = 1, se a >= t ou

- y = 0, se a < t.

  

A maioria dos modelos de redes neurais possui alguma regra de treinamento, onde os pesos de suas conex√µes s√£o ajustados de acordo com os padr√µes apresentados. Em outras palavras, elas aprendem atrav√©s de exemplos.

Arquiteturas neurais s√£o tipicamente organizadas em camadas, com unidades que podem estar conectadas √†s unidades da camada posterior.

![img](https://sites.icmc.usp.br/andre/research/neural/image/camadas_an.gif)

#### *Organiza√ß√£o em camadas.

*

Usualmente as camadas s√£o classificadas em tr√™s grupos:

- **Camada de Entrada**: onde os padr√µes s√£o apresentados √† rede;

  

- **Camadas Intermedi√°rias ou Escondidas**: onde √© feita a maior parte do processamento, atrav√©s das conex√µes ponderadas; podem ser consideradas como extratoras de caracter√≠sticas;

  

- **Camada de Sa√≠da**: onde o resultado final √© conclu√≠do e apresentado.

  

Uma rede neural √© especificada, principalmente pela sua topologia, pelas caracter√≠sticas dos n√≥s e pelas regras de treinamento. A seguir, ser√£o analisados os processos de aprendizado.



------

## **Processos de Aprendizado**


A propriedade mais importante das redes neurais √© a habilidade de aprender de seu ambiente e com isso melhorar seu desempenho. Isso √© feito atrav√©s de um processo iterativo de ajustes aplicado a seus pesos, o treinamento. O aprendizado ocorre quando a rede neural atinge uma solu√ß√£o generalizada para uma classe de problemas.

Denomina-se algoritmo de aprendizado a um conjunto de regras bem definidas para a solu√ß√£o de um problema de aprendizado. Existem muitos tipos de algoritmos de aprendizado espec√≠ficos para determinados modelos de redes neurais, estes algoritmos diferem entre si principalmente pelo modo como os pesos s√£o modificados.

Outro fator importante √© a maneira pela qual uma rede neural se relaciona com o ambiente. Nesse contexto existem os seguintes paradigmas de aprendizado:



- **Aprendizado Supervisionado**, quando √© utilizado um agente externo que indica √† rede a resposta desejada para o padr√£o de entrada;

  

- **Aprendizado N√£o Supervisionado** (auto-organiza√ß√£o), quando n√£o existe uma agente externo indicando a resposta desejada para os padr√µes de entrada;

  

- **Refor√ßo**, quando um cr√≠tico externo avalia a resposta fornecida pela rede.

Denomina-se ciclo uma apresenta√ß√£o de todos os N pares (entrada e sa√≠da) do conjunto de treinamento no processo de aprendizado. A corre√ß√£o dos pesos num ciclo pode ser executado de dois modos:

> **1) Modo Padr√£o**: A corre√ß√£o dos pesos acontece a cada apresenta√ß√£o √† rede de um exemplo do conjunto de treinamento. Cada corre√ß√£o de pesos baseia-se somente no erro do exemplo apresentado naquela itera√ß√£o. Assim, em cada ciclo ocorrem N corre√ß√µes.



- **2) Modo Batch**: Apenas uma corre√ß√£o √© feita por ciclo. Todos os exemplos do conjunto de treinamento s√£o apresentados √† rede, seu erro m√©dio √© calculado e a partir deste erro fazem-se as corre√ß√µes dos pesos.



------



## **Treinamento Supervisionado**


O treinamento supervisionado do modelo de rede Perceptron, consiste em ajustar os pesos e os thresholds de suas unidades para que a classifica√ß√£o desejada seja obtida. Para a adapta√ß√£o do threshold juntamente com os pesos podemos consider√°-lo como sendo o peso associado a uma conex√£o, cuja entrada √© sempre igual √† -1 e adaptar o peso relativo a essa entrada.

Quando um padr√£o √© inicialmente apresentado √† rede, ela produz uma sa√≠da. Ap√≥s medir a dist√¢ncia entre a resposta atual e a desejada, s√£o realizados os ajustes apropriados nos pesos das conex√µes de modo a reduzir esta dist√¢ncia.Este procedimento √© conhecido como Regra Delta.





![img](https://sites.icmc.usp.br/andre/research/neural/image/r_delta.jpg)



#### *Regra Delta*



Deste modo, temos o seguinte esquema de treinamento.

Iniciar todas as conex√µes com pesos aleat√≥rios;

Repita at√© que o erro E seja satisfatoriamente pequeno (E = e)

Para cada par de treinamento (X,d), fa√ßa:

Calcular a resposta obtida O;

Se o erro n√£o for satisfatoriamente pequeno E > e, ent√£o:

Atualizar pesos: Wnovo := W anterior + neta E X



### Onde:

- O par de treinamento (X, d) corresponde ao padr√£o de entrada e a sua respectiva resposta desejada;
- O erro E √© definido como: Resposta Desejada - Resposta Obtida (d - O);
- A taxa de aprendizado neta √© uma constante positiva, que corresponde √† velocidade do aprendizado.

![img](https://sites.icmc.usp.br/andre/research/neural/image/treina.jpg)

*Esquema de treinamento do Perceptron.*

As respostas geradas pelas unidades s√£o calculadas atrav√©s de uma fun√ß√£o de ativa√ß√£o. Existem v√°rios tipos de fun√ß√µes de ativa√ß√£o, as mais comuns s√£o: Hard Limiter, Threshold Logic e Sigmoid.

![img](https://sites.icmc.usp.br/andre/research/neural/image/tra_func.jpg)









#### AGRADECIMENTO ESPECIAL:   

https://github.com/Daniell-Dantas   (parceria e autor de parte)
